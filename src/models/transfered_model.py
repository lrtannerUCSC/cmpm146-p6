from models.model import Model
from tensorflow.keras import Sequential, layers, models
#from tensorflow.keras.layers.experimental.preprocessing import Rescaling
from tensorflow.keras.optimizers import RMSprop, Adam

class TransferedModel(Model):
    def _define_model(self, input_shape, categories_count):
        # Your code goes here
        # you have to initialize self.model to a keras model
        # load your basic model with keras's load_model function
        # freeze the weights of the loaded model to make sure the training doesn't affect them
        # (check the number of total params, trainable params and non-trainable params in your summary generated by train_transfer.py)
        # use this model by removing the last layer, adding dense layers and an output layer
        
        # initialize self.model to a keras model
        self.model = Sequential()

        # load your basic model with keras's load_model function (change me :D! basic_model_10_epochs_timestamp_1739904383.keras is the model it's currently using)
        base_model = models.load_model('TransferModel/transfer_model.keras')

        # removing the last layer
        for layer in base_model.layers[:-1]:
            self.model.add(layer)
        
        # freeze the weights of the loaded model to make sure the training doesn't affect them
        for layer in base_model.layers:
            layer.trainable = False

        # adding dense layers and an output layer
        self.model.add(layers.Dense(256, activation='relu', name='dense_1'))
        self.model.add(layers.Dropout(0.5, name='dropout_1'))
        self.model.add(layers.Dense(categories_count, activation='softmax', name='output_layer'))
    
    def _compile_model(self):
        # Your code goes here
        # you have to compile the keras model, similar to the example in the writeup
        # Compile the model with an appropriate optimizer and loss function
        self.model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])
